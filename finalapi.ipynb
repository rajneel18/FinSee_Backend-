{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install flask flask-cors pyngrok transformers torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T03:04:36.130975Z","iopub.execute_input":"2024-12-22T03:04:36.131152Z","iopub.status.idle":"2024-12-22T03:04:40.992843Z","shell.execute_reply.started":"2024-12-22T03:04:36.131135Z","shell.execute_reply":"2024-12-22T03:04:40.991849Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\nCollecting flask-cors\n  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\nCollecting pyngrok\n  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.4)\nRequirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\nDownloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok, flask-cors\nSuccessfully installed flask-cors-5.0.0 pyngrok-7.2.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# from pyngrok import ngrok\n# ngrok.set_auth_token('2pF3N7zzcGCvSRgHH4nnslwSruO_3eqjMZ45ZyViFnduoPVoU')\n\n!export NGROK_AUTH_TOKEN=\"2pF3N7zzcGCvSRgHH4nnslwSruO_3eqjMZ45ZyViFnduoPVoU\"  # Optional: Token is already included in the code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T03:04:40.993919Z","iopub.execute_input":"2024-12-22T03:04:40.994170Z","iopub.status.idle":"2024-12-22T03:04:41.108433Z","shell.execute_reply.started":"2024-12-22T03:04:40.994141Z","shell.execute_reply":"2024-12-22T03:04:41.107417Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T03:04:49.545656Z","iopub.execute_input":"2024-12-22T03:04:49.545936Z","iopub.status.idle":"2024-12-22T03:04:49.635786Z","shell.execute_reply.started":"2024-12-22T03:04:49.545915Z","shell.execute_reply":"2024-12-22T03:04:49.635141Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport os\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\nfrom pyngrok import ngrok\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Define model cache directory\nMODEL_CACHE_DIR = \"/kaggle/working/model_cache\"\nos.makedirs(MODEL_CACHE_DIR, exist_ok=True)\n\ndef generate_sample_transaction_history(num_transactions=20):\n    \"\"\"\n    Generate sample financial transaction history\n    \"\"\"\n    categories = [\n        'Groceries', 'Restaurant', 'Online Shopping', 'Utilities',\n        'Investment', 'Salary', 'Transfer', 'Entertainment',\n        'Healthcare', 'Travel'\n    ]\n    merchants = {\n        'Groceries': ['Walmart', 'Whole Foods', 'Trader Joe\\'s', 'Costco'],\n        'Restaurant': ['McDonald\\'s', 'Starbucks', 'Chipotle', 'Local Cafe'],\n        'Online Shopping': ['Amazon', 'eBay', 'Target Online', 'Best Buy'],\n        'Utilities': ['Electric Co.', 'Water Corp', 'Internet Service', 'Phone Bill'],\n        'Investment': ['Vanguard', 'Fidelity', 'Charles Schwab', 'Robinhood'],\n        'Salary': ['Employer Corp'],\n        'Transfer': ['Bank Transfer', 'Venmo', 'PayPal', 'Zelle'],\n        'Entertainment': ['Netflix', 'Spotify', 'Cinema', 'Gaming'],\n        'Healthcare': ['CVS Pharmacy', 'Medical Center', 'Dental Clinic'],\n        'Travel': ['Airlines', 'Hotels.com', 'Uber', 'Lyft']\n    }\n    \n    transactions = []\n    end_date = datetime.now()\n    start_date = end_date - timedelta(days=30)\n    current_balance = 5000\n    \n    for _ in range(num_transactions):\n        date = start_date + timedelta(days=random.randint(0, 30))\n        category = random.choice(categories)\n        merchant = random.choice(merchants[category])\n        \n        if category == 'Salary':\n            amount = random.uniform(3000, 5000)\n            transaction_type = 'credit'\n        elif category == 'Investment':\n            amount = random.uniform(100, 1000)\n            transaction_type = random.choice(['debit', 'credit'])\n        else:\n            amount = random.uniform(10, 500)\n            transaction_type = 'debit'\n        \n        if transaction_type == 'credit':\n            current_balance += amount\n        else:\n            current_balance -= amount\n        \n        transactions.append({\n            'date': date.strftime('%Y-%m-%d'),\n            'category': category,\n            'merchant': merchant,\n            'amount': round(amount, 2),\n            'type': transaction_type,\n            'balance': round(current_balance, 2)\n        })\n    \n    transactions.sort(key=lambda x: datetime.strptime(x['date'], '%Y-%m-%d'))\n    return transactions\n\nclass FinancialChatbot:\n    _instance = None\n    _model = None\n    _tokenizer = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(FinancialChatbot, cls).__new__(cls)\n        return cls._instance\n\n    def __init__(self):\n        if not hasattr(self, 'initialized'):\n            self.model_name = \"tiiuae/falcon-7b-instruct\"\n            self.transactions = generate_sample_transaction_history()\n            self.model_path = os.path.join(MODEL_CACHE_DIR, \"falcon-7b-instruct\")\n            self.load_model()\n            self.initialized = True\n\n    def load_model(self):\n        try:\n            if FinancialChatbot._model is None or FinancialChatbot._tokenizer is None:\n                logger.info(\"Loading Falcon-7B-Instruct model...\")\n                \n                # Check if model is cached\n                if os.path.exists(self.model_path):\n                    logger.info(\"Loading model from cache...\")\n                    self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n                    self.model = AutoModelForCausalLM.from_pretrained(\n                        self.model_path,\n                        device_map=\"auto\",\n                        torch_dtype=torch.float16\n                    )\n                else:\n                    logger.info(\"Downloading model and saving to cache...\")\n                    self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n                    self.model = AutoModelForCausalLM.from_pretrained(\n                        self.model_name,\n                        device_map=\"auto\",\n                        torch_dtype=torch.float16\n                    )\n                    # Save model and tokenizer to cache\n                    self.tokenizer.save_pretrained(self.model_path)\n                    self.model.save_pretrained(self.model_path)\n\n                FinancialChatbot._model = self.model\n                FinancialChatbot._tokenizer = self.tokenizer\n                logger.info(\"Model loaded successfully!\")\n            else:\n                logger.info(\"Using cached model instance...\")\n                self.model = FinancialChatbot._model\n                self.tokenizer = FinancialChatbot._tokenizer\n                \n        except Exception as e:\n            logger.error(f\"Error loading model: {str(e)}\")\n            raise\n\n    def format_transaction_history(self, transactions=None):\n        if transactions is None:\n            transactions = self.transactions\n        \n        df = pd.DataFrame(transactions)\n        total_income = df[df['type'] == 'credit']['amount'].sum()\n        total_expenses = df[df['type'] == 'debit']['amount'].sum()\n        current_balance = df.iloc[-1]['balance']\n        category_spending = df[df['type'] == 'debit'].groupby('category')['amount'].sum()\n        \n        summary = f\"\"\"\nTransaction History Summary:\n- Current Balance: ${current_balance:.2f}\n- Total Income: ${total_income:.2f}\n- Total Expenses: ${total_expenses:.2f}\n\nTop Spending Categories:\n{category_spending.sort_values(ascending=False).head(5).to_string()}\n\nRecent Transactions:\n{df.tail(5).to_string(index=False)}\n\"\"\"\n        return summary\n\n    def generate_response(self, user_query, transactions=None):\n        transaction_summary = self.format_transaction_history(transactions)\n        system_prompt = f\"\"\"You are Falcon Finance, a specialized financial AI assistant.\nHere is the user's transaction history:\n{transaction_summary}\n\nThe user asks: {user_query}\n\nProvide concise and personalized financial advice in 100-150 words.\nResponse:\"\"\"\n        try:\n            inputs = self.tokenizer(\n                system_prompt, \n                return_tensors=\"pt\", \n                max_length=1024, \n                truncation=True\n            ).to(self.model.device)\n            \n            outputs = self.model.generate(\n                **inputs,\n                max_length=500,\n                temperature=0.7,\n                top_p=0.9,\n                repetition_penalty=1.1\n            )\n            \n            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n            response = response.split(\"Response:\")[-1].strip()\n            return response, transaction_summary\n        except Exception as e:\n            logger.error(f\"Error generating response: {str(e)}\")\n            raise Exception(f\"Error generating response: {str(e)}\")\n\n# Flask application setup\napp = Flask(__name__)\n# CORS(app, \n#     resources={\n#         r\"/api/*\": {  # Apply to all /api/ routes\n#             \"origins\": [\"http://localhost:3000\", \"http://localhost:3000/assistant\" ],  # Add any other allowed origins as needed\n#             \"methods\": [\"GET\", \"POST\", \"OPTIONS\"],\n#             # \"allow_headers\": [\"Content-Type\", \"Authorization\"],\n#             # \"supports_credentials\": True\n#         }\n#     }\n# )\nchatbot = FinancialChatbot()\n\n@app.route('/')\ndef home():\n    return jsonify({\n        \"status\": \"success\",\n        \"message\": \"Financial Chatbot API is running\"\n    })\n\n@app.route('/chat', methods=['POST'])\ndef chat():\n    try:\n        data = request.get_json()\n        if not data or 'query' not in data:\n            return jsonify({\n                \"status\": \"error\",\n                \"message\": \"Query is required\"\n            }), 400\n\n        query = data['query']\n        transactions = data.get('transactions')  # Optional custom transactions\n        \n        response, summary = chatbot.generate_response(query, transactions)\n        \n        return jsonify({\n            \"status\": \"success\",\n            \"response\": response,\n            \"transaction_summary\": summary\n        })\n    except Exception as e:\n        logger.error(f\"Error in chat endpoint: {str(e)}\")\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": str(e)\n        }), 500\n\n@app.route('/transactions', methods=['GET'])\ndef get_transactions():\n    return jsonify({\n        \"status\": \"success\",\n        \"transactions\": chatbot.transactions\n    })\n\n@app.route('/health', methods=['GET'])\ndef health_check():\n    return jsonify({\n        \"status\": \"healthy\",\n        \"timestamp\": datetime.now().isoformat()\n    })\n\n# ... (previous imports remain the same)\n\ndef start_ngrok():\n    try:\n        # Use a default token or environment variable\n        auth_token = os.getenv(\"NGROK_AUTH_TOKEN\", \"2pF3N7zzcGCvSRgHH4nnslwSruO_3eqjMZ45ZyViFnduoPVoU\")\n        ngrok.set_auth_token(auth_token)\n        \n        # Kill any existing ngrok processes\n        ngrok.kill()\n        \n        # Start ngrok\n        tunnel = ngrok.connect(5000)\n        public_url = tunnel.public_url\n        \n        print(\"\\n\" + \"=\"*50)\n        print(f\"Public URL: {public_url}\")\n        print(\"=\"*50 + \"\\n\")\n        \n        logger.info(f\"Ngrok tunnel established at: {public_url}\")\n        return public_url\n    except Exception as e:\n        logger.error(f\"Ngrok startup failed: {str(e)}\")\n        raise\n\ndef main():\n    try:\n        # Print startup message\n        print(\"\\nStarting Financial Chatbot API...\")\n        \n        # Start ngrok tunnel\n        public_url = start_ngrok()\n        \n        # Print success message\n        print(\"\\nServer is ready!\")\n        print(f\"API is accessible at: {public_url}\")\n        print(\"\\nAvailable endpoints:\")\n        print(f\"- Chat: {public_url}/chat (POST)\")\n        print(f\"- Transactions: {public_url}/transactions (GET)\")\n        print(f\"- Health: {public_url}/health (GET)\")\n        print(\"\\nPress Ctrl+C to stop the server\\n\")\n        \n        # Run Flask app\n        app.run(host='0.0.0.0', port=5000)\n    except Exception as e:\n        logger.error(f\"Server startup failed: {str(e)}\")\n        print(f\"\\nError: {str(e)}\")\n        raise\n    finally:\n        ngrok.kill()\n\nif __name__ == \"__main__\":\n    # Install required packages if running in Kaggle\n    try:\n        print(\"\\nInstalling required packages...\")\n        import subprocess\n        subprocess.run([\"pip\", \"install\", \"flask\", \"flask-cors\", \"pyngrok\", \"transformers\", \"torch\"], \n                      capture_output=True)\n        print(\"Packages installed successfully!\")\n    except Exception as e:\n        logger.error(f\"Error installing packages: {str(e)}\")\n        print(f\"\\nError installing packages: {str(e)}\")\n\n    # Run the main application\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T03:18:24.807540Z","iopub.execute_input":"2024-12-22T03:18:24.807829Z","execution_failed":"2024-12-22T04:21:58.466Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"760d0986d5cd484897684315e1ef142e"}},"metadata":{}},{"name":"stdout","text":"\nInstalling required packages...\nPackages installed successfully!\n\nStarting Financial Chatbot API...\n\n==================================================\nPublic URL: https://745f-34-127-62-40.ngrok-free.app\n==================================================\n\n\nServer is ready!\nAPI is accessible at: https://745f-34-127-62-40.ngrok-free.app\n\nAvailable endpoints:\n- Chat: https://745f-34-127-62-40.ngrok-free.app/chat (POST)\n- Transactions: https://745f-34-127-62-40.ngrok-free.app/transactions (GET)\n- Health: https://745f-34-127-62-40.ngrok-free.app/health (GET)\n\nPress Ctrl+C to stop the server\n\n * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}